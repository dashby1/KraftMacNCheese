{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"otter":{"OK_FORMAT":true,"tests":{}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4526,"databundleVersionId":34463,"sourceType":"competition"},{"sourceId":9611126,"sourceType":"datasetVersion","datasetId":5864602}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CS4320 Introduction to Machine Learning\n\n## A Template for the Course Project Submssion\n\nNote: This template is optional. You can design your Jupyter Notebook structure based on your competition and preference. However, we expect you practice as many machine learning skills you learned in this course as possible.\n\n**Please type your group name here:**","metadata":{}},{"cell_type":"code","source":"GroupName = \"KraftMaacNCheese\"\nassert GroupName != \"\", 'Please enter your name in the above quotation marks, thanks!'\nKaggleCompetitionLink = \"https://www.kaggle.com/competitions/whats-cooking\"\nassert KaggleCompetitionLink != \"\", 'Please enter your name in the above quotation marks, thanks!'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:11:22.966683Z","iopub.execute_input":"2024-11-21T05:11:22.967245Z","iopub.status.idle":"2024-11-21T05:11:22.994572Z","shell.execute_reply.started":"2024-11-21T05:11:22.967205Z","shell.execute_reply":"2024-11-21T05:11:22.992589Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m GroupName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m GroupName \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease enter your name in the above quotation marks, thanks!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m KaggleCompetitionLink \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m KaggleCompetitionLink \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease enter your name in the above quotation marks, thanks!\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mAssertionError\u001b[0m: Please enter your name in the above quotation marks, thanks!"],"ename":"AssertionError","evalue":"Please enter your name in the above quotation marks, thanks!","output_type":"error"}],"execution_count":21},{"cell_type":"markdown","source":"## Table of contents\n0. [Submission instructions](#si)\n1. [Understanding the problem](#1)\n2. [Data splitting](#2)\n3. [EDA](#3)\n4. [Feature engineering](#4)\n5. [Preprocessing and transformations](#5) \n6. [Baseline model](#6)\n7. [Linear models](#7)\n8. [Different models](#8)\n9. [Feature selection](#9)\n10. [Hyperparameter optimization](#10)\n11. [Interpretation and feature importances](#11) \n12. [Results on the test set](#12)\n13. [Submit the predictions to Kaggle](#13)\n14. [Your takeaway from the course](#14)","metadata":{}},{"cell_type":"markdown","source":"## Submission instructions <a name=\"si\"></a>\n<hr>\n\n- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n- Upload the .ipynb file to Canvas.\n- **Submit the screenshot of your Kaggle submission ranking and score** \n- Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n- Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n- Make sure that the plots and output are rendered properly in your submitted file. \n- Please keep your notebook clean and delete any throwaway code.","metadata":{}},{"cell_type":"markdown","source":"## Introduction <a name=\"in\"></a>\n\nA few notes and tips when you work on this project: \n\n#### Tips\n1. The project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n\n#### Assessment\nWe plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport time\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score, cross_validate, train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MultiLabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nimport csv\nfrom xgboost import XGBClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:12:05.831710Z","iopub.execute_input":"2024-11-21T05:12:05.832138Z","iopub.status.idle":"2024-11-21T05:12:08.556209Z","shell.execute_reply.started":"2024-11-21T05:12:05.832096Z","shell.execute_reply":"2024-11-21T05:12:08.555152Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/whats-cooking/sample_submission.csv.zip\n/kaggle/input/whats-cooking/test.json.zip\n/kaggle/input/whats-cooking/train.json.zip\n/kaggle/input/unzipped/train.json\n/kaggle/input/unzipped/test.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Spend some time understanding the problem and what each feature means. Write a few sentences on your initial thoughts on the problem and the dataset. ","metadata":{}},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 2. Data splitting <a name=\"2\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Split the data into train and test portions.","metadata":{}},{"cell_type":"code","source":"df = pd.read_json(\"/kaggle/input/unzipped/train.json\")\ndf_test = pd.read_json(\"/kaggle/input/unzipped/test.json\")\n\nX = df.drop(columns=[\"cuisine\", \"id\"])\ny = df[\"cuisine\"]\ntest_id = df_test[\"id\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# X_test = df_test.drop(columns=[\"id\"])\n# test_id = df_test[\"id\"]\n# print(type(test_id))\nprint(X_train)\nprint(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:53:17.668554Z","iopub.execute_input":"2024-11-21T05:53:17.669392Z","iopub.status.idle":"2024-11-21T05:53:18.308750Z","shell.execute_reply.started":"2024-11-21T05:53:17.669347Z","shell.execute_reply":"2024-11-21T05:53:18.307660Z"}},"outputs":[{"name":"stdout","text":"                                             ingredients\n23436  [shredded cheddar cheese, chicken meat, choppe...\n7901   [fresh cilantro, purple onion, ground coriande...\n25718  [sugar, garlic, onions, vinegar, green chilies...\n16909  [raw pistachios, purple onion, couscous, dried...\n34830  [tomatoes, pepper, salsa, sliced green onions,...\n...                                                  ...\n6265   [tomato purée, butter, salt, taco seasoning, p...\n11284  [marsala wine, butter, olive oil, fresh mushro...\n38158  [blue crabs, peeled fresh ginger, soy sauce, s...\n860    [pepper, spicy brown mustard, boneless chicken...\n15795  [olive oil, thyme leaves, dried lavender, lemo...\n\n[31819 rows x 1 columns]\n23436        mexican\n7901          indian\n25718       filipino\n16909       moroccan\n34830        mexican\n            ...     \n6265         mexican\n11284        italian\n38158        chinese\n860      southern_us\n15795         french\nName: cuisine, Length: 31819, dtype: object\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 3. EDA <a name=\"3\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Perform exploratory data analysis on the train set.\n2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n3. Summarize your initial observations about the data. ","metadata":{}},{"cell_type":"code","source":"# Your code here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:11:23.001258Z","iopub.status.idle":"2024-11-21T05:11:23.001718Z","shell.execute_reply.started":"2024-11-21T05:11:23.001495Z","shell.execute_reply":"2024-11-21T05:11:23.001516Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 4. Feature engineering <a name=\"4\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set. You may have to go back and forth between feature engineering and preprocessing. Briefly explain why you come up with these new features.","metadata":{}},{"cell_type":"code","source":"ingredient_mapping = {\n    # Milk and Dairy Variants\n    \"whole milk\": \"milk\",\n    \"skim milk\": \"milk\",\n    \"2% milk\": \"milk\",\n    \"condensed milk\": \"milk\",\n    \"evaporated milk\": \"milk\",\n    \"cream cheese\": \"cheese\",\n    \"cheddar cheese\": \"cheese\",\n    \"parmesan cheese\": \"cheese\",\n    \"mozzarella cheese\": \"cheese\",\n    \"feta cheese\": \"cheese\",\n    \"yogurt\": \"yogurt\",\n    \"plain yogurt\": \"yogurt\",\n    \"greek yogurt\": \"yogurt\",\n\n    # Butter Variants\n    \"unsalted butter\": \"butter\",\n    \"salted butter\": \"butter\",\n    \"butter oil\": \"butter\",\n    \"margarine\": \"butter\",\n\n    # Tomato Sauce and Related Variants\n    \"tomato paste\": \"tomato sauce\",\n    \"marinara sauce\": \"tomato sauce\",\n    \"pasta sauce\": \"tomato sauce\",\n    \"tomato sauce\": \"tomato sauce\",\n    \"crushed tomatoes\": \"tomato\",\n    \"diced tomatoes\": \"tomato\",\n    \"plum tomatoes\": \"tomato\",\n\n    # Sugar Variants\n    \"white sugar\": \"sugar\",\n    \"brown sugar\": \"sugar\",\n    \"granulated sugar\": \"sugar\",\n    \"confectioners sugar\": \"sugar\",\n    \"powdered sugar\": \"sugar\",\n    \"dark brown sugar\": \"sugar\",\n\n    # Oil Variants\n    \"extra-virgin olive oil\": \"olive oil\",\n    \"vegetable oil\": \"oil\",\n    \"canola oil\": \"oil\",\n    \"peanut oil\": \"oil\",\n    \"sesame oil\": \"oil\",\n    \n    # Flour Variants\n    \"all-purpose flour\": \"flour\",\n    \"self rising flour\": \"flour\",\n    \"cake flour\": \"flour\",\n    \"bread flour\": \"flour\",\n\n    # Vinegar Variants\n    \"rice vinegar\": \"vinegar\",\n    \"apple cider vinegar\": \"vinegar\",\n    \"white vinegar\": \"vinegar\",\n    \"balsamic vinegar\": \"vinegar\",\n    \"red wine vinegar\": \"vinegar\",\n    \n    # Soy Sauce Variants\n    \"low sodium soy sauce\": \"soy sauce\",\n    \"light soy sauce\": \"soy sauce\",\n    \"dark soy sauce\": \"soy sauce\",\n}\n\n# Function to map ingredients in each recipe to broader categories\ndef map_ingredients(ingredients):\n    return [ingredient_mapping.get(ing, ing) for ing in ingredients]\n\n# Apply the mapping to the ingredients columns\nX_train['ingredients'] = X_train['ingredients'].apply(map_ingredients)\nX_test['ingredients'] = X_test['ingredients'].apply(map_ingredients)\n\nX_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:39:59.325611Z","iopub.execute_input":"2024-11-21T05:39:59.326046Z","iopub.status.idle":"2024-11-21T05:39:59.485964Z","shell.execute_reply.started":"2024-11-21T05:39:59.326005Z","shell.execute_reply":"2024-11-21T05:39:59.484834Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                             ingredients\n23436  [shredded cheddar cheese, chicken meat, choppe...\n7901   [fresh cilantro, purple onion, ground coriande...\n25718  [sugar, garlic, onions, vinegar, green chilies...\n16909  [raw pistachios, purple onion, couscous, dried...\n34830  [tomatoes, pepper, salsa, sliced green onions,...\n...                                                  ...\n6265   [tomato purée, butter, salt, taco seasoning, p...\n11284  [marsala wine, butter, olive oil, fresh mushro...\n38158  [blue crabs, peeled fresh ginger, soy sauce, s...\n860    [pepper, spicy brown mustard, boneless chicken...\n15795  [olive oil, thyme leaves, dried lavender, lemo...\n\n[31819 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23436</th>\n      <td>[shredded cheddar cheese, chicken meat, choppe...</td>\n    </tr>\n    <tr>\n      <th>7901</th>\n      <td>[fresh cilantro, purple onion, ground coriande...</td>\n    </tr>\n    <tr>\n      <th>25718</th>\n      <td>[sugar, garlic, onions, vinegar, green chilies...</td>\n    </tr>\n    <tr>\n      <th>16909</th>\n      <td>[raw pistachios, purple onion, couscous, dried...</td>\n    </tr>\n    <tr>\n      <th>34830</th>\n      <td>[tomatoes, pepper, salsa, sliced green onions,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6265</th>\n      <td>[tomato purée, butter, salt, taco seasoning, p...</td>\n    </tr>\n    <tr>\n      <th>11284</th>\n      <td>[marsala wine, butter, olive oil, fresh mushro...</td>\n    </tr>\n    <tr>\n      <th>38158</th>\n      <td>[blue crabs, peeled fresh ginger, soy sauce, s...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>[pepper, spicy brown mustard, boneless chicken...</td>\n    </tr>\n    <tr>\n      <th>15795</th>\n      <td>[olive oil, thyme leaves, dried lavender, lemo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>31819 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 5. Preprocessing and transformations <a name=\"5\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Identify different feature types and the transformations you would apply on each feature type. \n2. Define a column transformer, if necessary. ","metadata":{}},{"cell_type":"code","source":"mlb = MultiLabelBinarizer(sparse_output=True)\n\nX_train_ingredients = mlb.fit_transform(X_train['ingredients'])\nX_test_ingredients = mlb.transform(X_test['ingredients'])\n\ndense_matrix_from_sparse = X_train_ingredients.toarray()\n\n# Convert the dense matrix to a Pandas DataFrame\ndf = pd.DataFrame(dense_matrix_from_sparse)\n\n# Print the regular Pandas DataFrame\nprint(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:40:05.374159Z","iopub.execute_input":"2024-11-21T05:40:05.374572Z","iopub.status.idle":"2024-11-21T05:40:06.517101Z","shell.execute_reply.started":"2024-11-21T05:40:05.374533Z","shell.execute_reply":"2024-11-21T05:40:06.515837Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Alexia Waffle Fries', 'BACARDI® Mixers Margarita Mix', 'BACARDI® Superior', \"BREAKSTONE'S Sour Cream\", 'Better Than Bouillon Chicken Base', 'Bragg Liquid Aminos', 'Crystal Farms Reduced Fat Shredded Marble Jack Cheese', 'Crystal Farms Shredded Gouda Cheese', 'DeLallo Penne Ziti', 'Elmlea Single Light', 'Elmlea single', 'Fisher Pecan Halves', 'Flora Buttery', 'Flora pro.activ', 'Greek black olives', 'Hidden Valley® Greek Yogurt Original Ranch® Dip Mix', 'JOHNSONVILLE Hot & Spicy Sausage Slices', 'Jell-O Gelatin Dessert', 'Jif Creamy Peanut Butter', 'Jimmy Dean All Natural Regular Pork Sausage', 'KNUDSEN 2% Milkfat Low Fat Cottage Cheese', 'KRAFT Mexican Style Shredded Four Cheese with a TOUCH OF PHILADELPHIA', 'KRAFT Reduced Fat Shredded Mozzarella Cheese', 'KRAFT Shredded Mozzarella Cheese', 'Knorr® Pasta Sides™ - Butter & Herb', 'Mae Ploy Sweet Chili Sauce', 'McCormick Ground White Pepper', 'McCormick Poppy Seed', 'McCormick® Pure Vanilla Extract', 'Mexican lager beer', 'Mission Corn Tortillas', 'Nido Milk Powder', 'Old El Paso™ mild red enchilada sauce', 'Pillsbury Pie Crusts', 'Progresso Black Beans', 'Progresso™ Chicken Broth', 'Quorn crumbles', 'Ragu Classic Alfredo Sauce', 'Ragu Golden Veggie Fettuccine Pasta', 'Ragu Traditional Sauce', 'Robert Mondavi Fume Blanc', 'Rotel Diced Tomatoes & Green Chilies', 'San Marzano Diced Tomatoes', 'Soy Vay® Hoisin Garlic Marinade & Sauce', 'Soy Vay® Veri Veri Teriyaki® Marinade & Sauce', 'Spice Islands Garlic Salt', 'Spice Islands Ground Cumin Seed', 'Sugar in the Raw', 'Swanson Vegetable Broth', 'Tuaca Liqueur', 'Tuttorosso Diced Tomatoes', 'V8 Juice', 'Wish-Bone Light Italian Dressing', 'Wish-Bone® Robusto Italian Dressing', 'Zatarains Creole Seasoning', 'adobo style seasoning', 'aleppo', 'amaranth', 'amber rum', 'ammonium bicarbonate', 'and carrot green pea', 'anise basil', 'artisan bread', 'asian black bean sauce', 'asian wheat noodles', 'baby beets', 'baby goat', 'banana bread', 'banana extract', 'banana flower', 'barramundi fillets', 'beer batter', 'belacan', 'bertolli organic tradit sauc', 'black radish', 'black sea bass', 'blanco chees queso', 'bock beer', 'boneless moulard duck breast halves', 'bottled low sodium salsa', 'bran flakes', 'branca menta', 'breakfast sausage links', 'buckwheat groats', 'buckwheat honey', 'burger rolls', 'butter flavor shortening', 'butter flavor vegetable shortening', 'butter salt', 'bâtarde', 'cactus', 'cactus leaf', 'calabash', 'canned chicken breast', 'cappuccino', 'caramel flavored syrup', 'cardoons', 'carrot greens', 'carrot juice', 'cashew milk', 'cassis liqueur', 'ceci bean', 'celery tops', 'center cut pork roast', 'cereal', 'chestnut flour', 'chicken and rice soup', 'chicken egg', 'chicken flavored rice', 'chilean sea bass fillets', 'chinese hot mustard', 'chive blossoms', 'chocolate chip cookie dough ice cream', 'chocolate frosting', 'chocolate sticks', 'chocolatecovered espresso beans', 'chuck short ribs', 'ciabatta roll', 'cinnamon ice cream', 'cipollini', 'clementine juice', 'clementine sections', 'coconut chips', 'cola-flavored carbonated beverage', 'coleslaw dressing', 'condensed cream of broccoli soup', 'cooki vanilla wafer', 'corn niblets', 'cornstarch noodles', 'crab sticks', 'cracked wheat', 'cream of tomato soup', 'creole seafood seasoning', 'crumpet', 'crusty loaf', 'cubed mango', 'cubed pancetta', 'culinary lavender', 'cured meats', 'cuttlefish balls', 'daikon sprouts', 'dairy free coconut ice cream', 'dandelion', 'dangmyun', 'delicata squash', 'demi baguette', 'dhaniya powder', 'dipping chocolate', 'do chua', 'double smoked bacon', 'dried neem leaves', 'dried oysters', 'dried strawberries', 'duxelles', 'egg pasta', 'energy drink', 'english breakfast tea bags', 'english walnuts', 'european style butter', 'fat-free croutons', 'fiddlehead ferns', 'fideos pasta', 'fillet medallions', 'fillet of beef', 'filling', 'fine grind white cornmeal', 'flavored tortilla chips', 'flavored wine', 'flower petals', 'frankfurters', 'fresh flounder fillets', 'fresh ham', 'friselle', 'frozen cranberry juice concentrate', 'frozen lemonade concentrate, thawed and undiluted', 'frozen mini ravioli', 'frozen onion rings', 'fruit filling', 'fruit puree', 'fudge cake mix', 'game', 'garbanzo bean flour', 'garlic olive oil', 'gelatin sheet', 'genmai miso', 'george dickel', 'ginkgo nut', 'gluten-free oat', 'gnocchetti sardi', 'goat milk feta', 'goat s milk cheese', 'goma', 'goose liver', 'graham cracker pie crust', 'grain alcohol', 'granular no-calorie sucralose sweetener', 'grape vine leaves', 'grilled chicken strips', 'ground hazelnuts', 'ground nuts', 'ground turkey sausage', 'guanabana', 'hamachi fillets', 'havarti', 'hazelnut flour', 'heirloom squash', 'hen of the woods', 'herb dressing', 'herb vinegar', 'high gluten bread flour', 'honey graham crackers', 'honeycomb tripe', 'hot italian pork sausage', 'hot spanish paprika', 'hots', 'instant butterscotch pudding mix', 'instant chicken bouillon', 'italian pizza crust', 'japanese radish', 'japanese style bread crumbs', 'kashmiri chile', 'katsuo bushi', 'kielbasa (not low fat)', 'kim chee', 'king salmon', 'lamb bouillon cube', 'lambrusco', 'less sodium mushroom flavored soy sauce', 'lesser galangal', 'light brown muscavado sugar', 'light kidney beans', 'lingcod', 'liquorice', 'long green pepper', 'lotus leaves', 'low fat monterey jack cheese', 'low sodium beef bouillon granules', 'low sodium diced tomatoes', 'low sodium fat free vegetable broth', 'low-fat chicken broth', 'low-fat parmesan cheese', 'low-fat salad dressing', 'low-fat soft goat cheese', 'low-fat vanilla ice cream', 'low-fat vegetable primavera spaghetti sauce', 'macaroni and cheese dinner', 'madagascar bourbon vanilla extract', 'malt powder', 'marrons', 'matsutake mushrooms', 'meat seasoning', 'meat-filled tortellini', 'mellow white miso', 'membrillo', 'mesquite flavored seasoning mix', 'mexican cooking sauce', 'milk chocolate kisses', 'mincemeat pie filling', 'mint extract', 'miso sesame grilling sauce', 'muscadet', 'muscovy', 'new mexico red chile powder', 'nian gao', 'no-calorie sweetener', 'nonfat mozzarella cheese', 'nonfat vanilla yogurt', 'ocean perch', 'one third less sodium chicken broth', 'organic butter', 'organic buttermilk', 'organic vegetable stock', 'oriental radish', 'osetra caviar', 'padron peppers', 'pain au levain', 'pancit', 'pasilla chile pepper', 'pasta wagon wheel', 'peach sorbet', 'peaches in light syrup', 'peanut brittle', 'pearl rice', 'pecan pie', 'peeled diced tomatoes', 'petits pois', 'petrale sole', 'pickle wedges', 'pimenton de la vera', 'pina colada mix', 'pink food coloring', 'pink salt', 'pisco brandy', 'pointed peppers', 'poppyseeds', 'pork roll', 'pork sausage casing', 'potato starch flour', 'poundcake', 'praline', 'prepared coleslaw', 'preshred low fat mozzarella chees', 'prune juice', 'psyllium husks', 'puff pastry cups', 'pumpkin seed mole', 'quahog clams', 'ranch dip', 'raspberry lambic', 'raspberry sherbet', 'red drum', 'red mullet', 'red mustard', 'reduced fat cream of mushroom soup', 'reduced sodium beef stock', 'reduced sodium ham', 'reduced sodium kidney beans', 'reduced sodium vegetable stock', 'reduced sugar ketchup', 'refined sugar', 'regular chicken broth', 'rice milk', 'rice mix', 'riso', 'roast pork seasoning mix', 'roasted ground cumin', 'romana', 'royal olives', 'salt water', 'sandwich steak', 'sandwich wraps', 'scape pesto', 'scrod', 'sea bream', 'seasoned ground turkey', 'seasoned panko bread crumbs', 'sesame seed paste', 'sesame seeds buns', 'seville orange juice', 'shaved chocolate', 'sherbet', 'shortbread', 'shoulder steak', 'shrimp chips', 'sichuan peppercorn oil', 'skinless chicken breast fillets', 'skinless haddock', 'skinned boned duck breast halves', 'slider rolls', 'small shells', 'smoked bratwurst', 'smoked rashers', 'smoked turkey drumstick', 'snow pea pods', 'sobrasada', 'solid white tuna in oil', 'soy marinade', 'soya cheese', 'sparkling rosé wine', 'sports drink', 'strained yogurt', 'suckling pig', 'sumac powder', 'sun dried tomato dressing', 'swanson beef broth', 'sweet & sour stir fry sauce', 'taco seasoned cheese', 'tallow', 'tangzhong roux', 'tea cake', 'teff', 'thick curds', 'ti leaves', 'toffee sauce', 'tomato jam', 'topside steak', 'tuaca', 'tuna drained and flaked', 'turkey burger', 'turkey gravy', 'turkey mince', 'unagi', 'unsweetened baking chocolate', 'unsweetened vanilla almond milk', 'v 8 juice', 'val', 'vanilla almondmilk', 'vanilla frozen yogurt', 'veal loin', 'vegan coffee creamer', 'vegetable-filled ravioli', 'vegetarian chicken', 'venison roast', 'vodka sauce', 'white almond bark', 'white bread slices', 'white quinoa', 'whole grain roll', 'whole grain spelt flour', 'whole turkey', 'whole wheat crackers', 'whole wheat english muffins', 'whole wheat fusilli', 'whole wheat spaghettini', 'won ton skins', 'wondra', 'wood mushrooms', 'yellow heirloom tomatoes', 'young coconut meat', 'young nettle', 'yucca'] will be ignored\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"       0     1     2     3     4     5     6     7     8     9     ...  6251  \\\n0         0     0     0     0     0     0     0     0     0     0  ...     0   \n1         0     0     0     0     0     0     0     0     0     0  ...     0   \n2         0     0     0     0     0     0     0     0     0     0  ...     0   \n3         0     0     0     0     0     0     0     0     0     0  ...     0   \n4         0     0     0     0     0     0     0     0     0     0  ...     0   \n...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n31814     0     0     0     0     0     0     0     0     0     0  ...     0   \n31815     0     0     0     0     0     0     0     0     0     0  ...     0   \n31816     0     0     0     0     0     0     0     0     0     0  ...     0   \n31817     0     0     0     0     0     0     0     0     0     0  ...     0   \n31818     0     0     0     0     0     0     0     0     0     0  ...     0   \n\n       6252  6253  6254  6255  6256  6257  6258  6259  6260  \n0         0     0     0     0     0     0     0     0     0  \n1         0     0     0     0     0     0     0     0     0  \n2         0     0     0     0     0     0     0     0     0  \n3         0     0     0     0     0     0     0     0     0  \n4         0     0     0     0     0     0     0     0     0  \n...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n31814     0     0     0     0     0     0     0     0     0  \n31815     0     0     0     0     0     0     0     0     0  \n31816     0     0     0     0     0     0     0     0     0  \n31817     0     0     0     0     0     0     0     0     0  \n31818     0     0     0     0     0     0     0     0     0  \n\n[31819 rows x 6261 columns]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 6. Baseline model <a name=\"6\"></a>\n<hr>\n\n**Your tasks:**\n1. Try `scikit-learn`'s baseline model and report results.","metadata":{}},{"cell_type":"code","source":"baseline_model = DummyClassifier(random_state=42)\n\nbaseline_model.fit(X_train_ingredients, y_train)\n\n# Make predictions on the test set\ny_pred = baseline_model.predict(X_test_ingredients)\n\n# Evaluate the model\nscores = cross_val_score(baseline_model, X_train_ingredients, y_train, cv=10, scoring='accuracy')\n\nprint(\"Decision Tree Accuracy:\", scores.mean())\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"test Accuracy: \", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:22:49.829260Z","iopub.execute_input":"2024-11-21T06:22:49.829697Z","iopub.status.idle":"2024-11-21T06:22:50.557459Z","shell.execute_reply.started":"2024-11-21T06:22:49.829661Z","shell.execute_reply":"2024-11-21T06:22:50.556311Z"}},"outputs":[{"name":"stdout","text":"Decision Tree Accuracy: 0.19708350433148103\ntest Accuracy:  0.19698302954116909\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 7. Linear models <a name=\"7\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Try a linear model as a first real attempt. \n2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n3. Report cross-validation scores along with standard deviation. \n4. Summarize your results.","metadata":{}},{"cell_type":"code","source":"linear_model = LogisticRegression(max_iter=1000, random_state=42)\n\n# Fit the model to the training data\nlinear_model.fit(X_train_ingredients, y_train)\n\n# Make predictions on the test set\ny_pred = linear_model.predict(X_test_ingredients)\n\n# Evaluate the model\nscores = cross_val_score(linear_model, X_train_ingredients, y_train, cv=5, scoring='accuracy')\n\nprint(\"Decision Tree Accuracy:\", scores.mean())\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"test Accuracy: \", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:23:04.386129Z","iopub.execute_input":"2024-11-21T06:23:04.386506Z","iopub.status.idle":"2024-11-21T06:27:33.967172Z","shell.execute_reply.started":"2024-11-21T06:23:04.386475Z","shell.execute_reply":"2024-11-21T06:27:33.965650Z"}},"outputs":[{"name":"stdout","text":"Decision Tree Accuracy: 0.7693831776550389\ntest Accuracy:  0.7807668133249529\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 8. Different models <a name=\"8\"></a>\n<hr>\n\n**Your tasks:**\n1. Try other models aside from a linear model. One of these models should be a tree-based ensemble model. \n2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? ","metadata":{}},{"cell_type":"code","source":"# Decision Tree\n\ndt_model = DecisionTreeClassifier(random_state=42)\n\n# Perform GridSearchCV for hyperparameter optimization\n\ndt_model.fit(X_train_ingredients, y_train)\n\ny_pred = dt_model.predict(X_test_ingredients)\n\n# Evaluate the model\nscores = cross_val_score(dt_model, X_train_ingredients, y_train, cv=5, scoring='accuracy')\n\nprint(\"Decision Tree Accuracy:\", scores.mean())\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"test Accuracy: \", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:06:33.510269Z","iopub.execute_input":"2024-11-21T06:06:33.510664Z","iopub.status.idle":"2024-11-21T06:07:01.256879Z","shell.execute_reply.started":"2024-11-21T06:06:33.510629Z","shell.execute_reply":"2024-11-21T06:07:01.255819Z"}},"outputs":[{"name":"stdout","text":"Decision Tree Accuracy: 0.5959960865440949\ntest Accuracy:  0.6079195474544312\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Random Forest\n\nrf_model = RandomForestClassifier(random_state=42)\n\n# Define the hyperparameter grid\n# param_grid = {\n#     'n_estimators': [50, 100, 200],             # Number of trees in the forest\n#     'max_depth': [None, 10, 20, 30],            # Maximum depth of the trees\n#     'min_samples_split': [2, 5, 10],            # Minimum samples required to split an internal node\n#     'min_samples_leaf': [1, 2, 4],              # Minimum samples required for a leaf node\n# }\n\n# Perform GridSearchCV for hyperparameter optimization\n# grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n# grid_search.fit(X_train_ingredients, y_train)\nrf_model.fit(X_train_ingredients, y_train)\n\n# Retrieve the best model from GridSearchCV\n# best_model = grid_search.best_estimator_\n\ny_pred = rf_model.predict(X_test_ingredients)\n\n# Evaluate the model\nscores = cross_val_score(rf_model, X_train_ingredients, y_train, cv=5, scoring='accuracy')\n\nprint(\"Decision Tree Accuracy:\", scores.mean())\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"test Accuracy: \", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:08:51.511781Z","iopub.execute_input":"2024-11-21T06:08:51.512705Z","iopub.status.idle":"2024-11-21T06:14:33.920918Z","shell.execute_reply.started":"2024-11-21T06:08:51.512663Z","shell.execute_reply":"2024-11-21T06:14:33.919858Z"}},"outputs":[{"name":"stdout","text":"Decision Tree Accuracy: 0.7021277403847056\ntest Accuracy:  0.7160276555625393\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# K Nearest Neighbors\n\nknn_model = KNeighborsClassifier()\n\n# Define the hyperparameter grid\n# param_grid = {\n#     'n_neighbors': [3, 5, 7, 9],              # Number of neighbors to consider\n#     'weights': ['uniform', 'distance'],       # Uniform weights or distance-based weights\n#     'metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics\n# }\n\n# Perform GridSearchCV for hyperparameter optimization\n# grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n# grid_search.fit(X_train_ingredients, y_train)\n\nknn_model.fit(X_train_ingredients, y_train)\n\n# Retrieve the best model from GridSearchCV\n# best_model = grid_search.best_estimator_\n\ny_pred = knn_model.predict(X_test_ingredients)\n\n# Evaluate the model\nscores = cross_val_score(knn_model, X_train_ingredients, y_train, cv=5, scoring='accuracy')\nprint(\"Decision Tree Accuracy:\", scores.mean())\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"test Accuracy: \", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:55:10.710527Z","iopub.execute_input":"2024-11-21T06:55:10.710920Z","iopub.status.idle":"2024-11-21T06:55:57.472637Z","shell.execute_reply.started":"2024-11-21T06:55:10.710885Z","shell.execute_reply":"2024-11-21T06:55:57.471426Z"}},"outputs":[{"name":"stdout","text":"Decision Tree Accuracy: 0.48172510031823873\ntest Accuracy:  0.4966687617850409\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# XGBoost\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.fit_transform(y_test)\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n\n# Define the hyperparameter grid\n# param_grid = {\n#     'n_estimators': [50, 100, 200],          # Number of boosting rounds\n#     'max_depth': [3, 5, 7],                  # Maximum tree depth\n#     'gamma': [0, 1, 5],                      # Minimum loss reduction to split a leaf node\n# }\n\n# Perform GridSearchCV for hyperparameter optimization\n# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n# grid_search.fit(X_train_ingredients, y_train_encoded)\nxgb_model.fit(X_train_ingredients, y_train_encoded)\n# Retrieve the best model from GridSearchCV\n# best_model = grid_search.best_estimator_\n\ny_pred = xgb_model.predict(X_test_ingredients)\n\n\n# Evaluate the model\n\nscores = cross_val_score(rf_model, X_train_ingredients, y_train_encoded, cv=5, scoring='accuracy')\n\nprint(\"XGB Accuracy:\", scores.mean())\n\naccuracy = accuracy_score(y_test_encoded, y_pred)\nprint(\"XGB Accuracy (Logistic Regression):\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:31:26.080212Z","iopub.execute_input":"2024-11-21T06:31:26.081311Z","iopub.status.idle":"2024-11-21T06:36:23.028732Z","shell.execute_reply.started":"2024-11-21T06:31:26.081268Z","shell.execute_reply":"2024-11-21T06:36:23.027611Z"}},"outputs":[{"name":"stdout","text":"XGB Accuracy: 0.7021277403847056\nXGB Accuracy (Logistic Regression): 0.7532369578881207\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"#Cat Boost\n\ncatboost_model = CatBoostClassifier(verbose=0, random_state=42)\n\nparam_grid = {\n    'iterations': [100, 200, 500],            # Number of boosting iterations\n    'learning_rate': [0.01, 0.1, 0.2],       # Learning rate (step size shrinkage)\n    'depth': [3, 5, 7],                      # Maximum tree depth\n    'l2_leaf_reg': [1, 3, 5],                # L2 regularization coefficient\n    'bagging_temperature': [0, 1, 3],        # Strength of the sampling\n}\n\n# Perform GridSearchCV for hyperparameter optimization\ngrid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n# Retrieve the best model from GridSearchCV\nbest_model = grid_search.best_estimator_\n\ny_pred = best_model.predict(X_test_ingredients)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"catboost Accuracy (Logistic Regression):\", accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 9. Feature selection <a name=\"9\"></a>\n<hr>\n\n**Your tasks:**\n\nMake some attempts to select relevant features. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it. ","metadata":{}},{"cell_type":"code","source":"# Your code here","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 10. Hyperparameter optimization <a name=\"10\"></a>\n<hr>\n\n**Your tasks:**\n\nMake some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) ","metadata":{}},{"cell_type":"code","source":"# Your code here","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 11. Interpretation and feature importances <a name=\"11\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to examine the most important features of one of the non-linear models. \n2. Summarize your observations. ","metadata":{}},{"cell_type":"code","source":"# Your code here","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 12. Results on the test set <a name=\"12\"></a>\n<hr>\n\n**Your tasks:**\n\n1. Try your best performing model on the test data (from train test split) and report test scores. \n2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n3. Take one or two test predictions and explain these individual predictions (e.g., with SHAP force plots).  ","metadata":{"tags":[]}},{"cell_type":"code","source":"# Your code here","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"_Type your answer here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 13. Submit the predictions to Kaggle <a name=\"13\"></a>\n<hr>\n\n**Your tasks:**\n\nRetrain the best model on the whole training dataset and upload the predicted output on the test set to Kaggle. Report your final test score.","metadata":{}},{"cell_type":"code","source":"# Your code here\nfrom sklearn.metrics import accuracy_score\n\nresults = xgb_model.predict(X_test_ingredients)\nresults_df = pd.DataFrame({\n    'cuisine': results.\n})\ndata = test_id.to_frame()\ndata['cuisine'] = results_df['cuisine']\nprint(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:55:12.942023Z","iopub.execute_input":"2024-11-21T05:55:12.942435Z","iopub.status.idle":"2024-11-21T05:55:13.427136Z","shell.execute_reply.started":"2024-11-21T05:55:12.942398Z","shell.execute_reply":"2024-11-21T05:55:13.425984Z"}},"outputs":[{"name":"stdout","text":"         id  cuisine\n0     18009      3.0\n1     28583     17.0\n2     41580      6.0\n3     29752      7.0\n4     35687      9.0\n...     ...      ...\n9939  30246      NaN\n9940  36028      NaN\n9941  22339      NaN\n9942  42525      NaN\n9943   1443      NaN\n\n[9944 rows x 2 columns]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"filename = 'submission.csv'\n\ndata.to_csv(filename, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T05:53:29.168987Z","iopub.execute_input":"2024-11-21T05:53:29.169376Z","iopub.status.idle":"2024-11-21T05:53:29.187130Z","shell.execute_reply.started":"2024-11-21T05:53:29.169342Z","shell.execute_reply":"2024-11-21T05:53:29.186011Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"_Place the Kaggle screenshot here, replacing this text._","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}},{"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n## 14. Your takeaway <a name=\"14\"></a>\n<hr>\n\n**Your tasks:**\n\nWhat is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers.  Discuss other ideas that you did not try but could potentially improve the performance/interpretability . ","metadata":{}},{"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<br><br>","metadata":{}}]}